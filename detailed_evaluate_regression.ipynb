{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91bafb42",
   "metadata": {},
   "source": [
    "## Evaluations using the \"super\" dataset, to plot some dependencies on exponents, models or noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c38beec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from swag.posteriors import swag as swag\n",
    "\n",
    "from load_andi_dataset import *\n",
    "from LSTM_Neural_Network import *\n",
    "from swag_lr_scheduler import *\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5847c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration, run on gpu if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dim = 1#2\n",
    "# Hyper-parameters, neuralnet parameters need to match the loaded model! \n",
    "input_dim = dim # 1D input sequence\n",
    "LSTM_size = [128,128,64]\n",
    "output_dim = 2 #output size\n",
    "batch_size = 500\n",
    "\n",
    "\n",
    "number_swags = 5 #number of swag models in multi swag ensemble\n",
    "number_mc_samples = 10 #number of samples taken per swag model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da9ae76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) [1] and dimension(s) [1].\n",
      "Generating dataset for dimension 1.\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "#setup data using saved trajectories\n",
    "T = 999#10#25#250#250#500#100\n",
    "noise_T = T\n",
    "N_test = 100000\n",
    "N_save = 2000\n",
    "task = 1\n",
    "use_increments = True\n",
    "\n",
    "test_path = f\"datasets/trajectories/{dim}d/validset/\"\n",
    "if dim == 1:\n",
    "    test_path = f\"datasets/trajectories/validset/\"\n",
    "super_dataset = AnDi_super_dataset_from_saved_trajs(path = test_path, task = task, dim = dim, N_total = N_test, \n",
    "                                              T = T, N_save = N_save, use_increments = use_increments)\n",
    "print(len(super_dataset))\n",
    "#loader\n",
    "super_loader = torch.utils.data.DataLoader(dataset=super_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f6a8fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) tensor([0.3000]) tensor(1.) tensor([[-1.5458],\n",
      "        [ 1.8552],\n",
      "        [ 1.1890],\n",
      "        [ 0.9564],\n",
      "        [-0.1254]])\n"
     ]
    }
   ],
   "source": [
    "#check dataset example\n",
    "ex_models,ex_exponents,ex_noise,ex_traj = iter(super_loader).next()\n",
    "print(ex_models[0],ex_exponents[0],ex_noise[0],ex_traj[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e420a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model:\n",
    "checkpoints_path = f\"saves/aleatoric/{dim}d/{T}_lenght/multi/\"\n",
    "if dim == 1:\n",
    "    checkpoints_path = f\"saves/aleatoric/{T}_lenght/multi/\"\n",
    "\n",
    "\n",
    "#swag_model = swag.SWAG(LSTM_Regression_aleatoric, subspace_type = 'covariance', \n",
    "#                       subspace_kwargs={'max_rank': 20}, num_input_features = input_dim, \n",
    "#                      output_dim = output_dim, LSTM_size=LSTM_size)\n",
    "#swag_model.to(device)\n",
    "\n",
    "#swag_model.subspace.rank = torch.tensor(0)\n",
    "#swag_model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "#swag_model.eval()\n",
    "\n",
    "multi_swag_models = []\n",
    "for i in range(number_swags):\n",
    "    swag_model = swag.SWAG(LSTM_Regression_aleatoric, subspace_type = 'covariance', \n",
    "                       subspace_kwargs={'max_rank': 20}, num_input_features = input_dim, \n",
    "                      output_dim = output_dim, LSTM_size=LSTM_size)\n",
    "    swag_model.to(device)\n",
    "    swag_model.subspace.rank = torch.tensor(0)\n",
    "    \n",
    "    \n",
    "    name = \"swag_modelcheckpoint_multiswag%s\" % i\n",
    "    savefile = checkpoints_path + name\n",
    "    \n",
    "    swag_model.load_state_dict(torch.load(savefile,map_location=device))\n",
    "    \n",
    "    swag_model.eval()\n",
    "    \n",
    "    \n",
    "    multi_swag_models.append(swag_model)\n",
    "\n",
    "\n",
    "#mse loss and Gaussian negative log likelihood criterion\n",
    "MSELoss = nn.MSELoss()\n",
    "criterion = torch.nn.GaussianNLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0a6431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 200/200 [18:10<00:00,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of the network on the 100000 test trajectories: 0.09752078624725342\n",
      "Mean loss is: -1.7625521695613862\n",
      "Mean Squared Error is: 0.022180743515491486\n",
      "Mean Variance predicted by SWAG is: 0.02376385274887085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test multi swag model on super data set\n",
    "n_test_steps = len(super_loader)\n",
    "n_total_samples = len(super_dataset)\n",
    "number_swags = len(multi_swag_models)\n",
    "\n",
    "target_values = torch.zeros(n_test_steps,batch_size).to(device)\n",
    "pred_values = torch.zeros(n_test_steps,batch_size).to(device)\n",
    "pred_std = torch.zeros(n_test_steps,batch_size).to(device)\n",
    "all_models = np.array([])\n",
    "all_noises = np.array([])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_abserr = 0\n",
    "    n_samples = 0\n",
    "    acc_loss = 0\n",
    "    acc_pred_var = 0\n",
    "    acc_mse = 0\n",
    "    for j, (models, targets, noise, traj) in enumerate(tqdm(super_loader)):\n",
    "        all_models = np.append(all_models,models)\n",
    "        all_noises = np.append(all_noises,noise)\n",
    "        traj = traj.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        output_samples = torch.ones(number_swags*number_mc_samples, len(traj), 1, dtype=torch.float32).to(device)\n",
    "        variance_samples = torch.ones(number_swags*number_mc_samples, len(traj), 1, dtype=torch.float32).to(device)\n",
    "        for k in range(number_swags):\n",
    "            for i in range(number_mc_samples):\n",
    "                multi_swag_models[k].sample()\n",
    "                model_output = multi_swag_models[k](traj)\n",
    "                output_samples[k*number_mc_samples+i] = model_output[:,0].view(-1,1)\n",
    "                variance_samples[k*number_mc_samples+i] = model_output[:,1].view(-1,1)\n",
    "        \n",
    "        outputs = output_samples.mean(0)\n",
    "        outputted_var = variance_samples.mean(0)\n",
    "        combined_var = output_samples.var(0) + outputted_var\n",
    "        \n",
    "        target_values[j] = targets.view(len(traj))\n",
    "        pred_values[j] = outputs.view(len(traj))\n",
    "        pred_std[j] = torch.sqrt(combined_var).view(len(traj))\n",
    "        \n",
    "        acc_pred_var += combined_var.sum().item()\n",
    "        \"\"\"if epoch+1 >= swag_start:\n",
    "            swag_model.set_swa()\n",
    "            outputs = swag_model(traj)\n",
    "        else:\n",
    "            outputs = model(traj)\"\"\"\n",
    "            \n",
    "        acc_loss += criterion(outputs, targets, outputted_var).item()\n",
    "        acc_mse += MSELoss(outputs,targets)\n",
    "        n_samples += targets.size(0)\n",
    "        n_abserr += (outputs-targets).abs().sum().item()\n",
    "        \n",
    "\n",
    "    MAE = n_abserr / n_samples\n",
    "    mean_loss = acc_loss/n_test_steps\n",
    "    mean_pred_var = acc_pred_var/n_samples\n",
    "    mean_mse = acc_mse/n_test_steps\n",
    "    print(f'MAE of the network on the 100000 test trajectories: {MAE}')\n",
    "    print(f'Mean loss is: {mean_loss}')\n",
    "    print(f'Mean Squared Error is: {mean_mse}')\n",
    "    print(f'Mean Variance predicted by SWAG is: {mean_pred_var}')\n",
    "    \n",
    "target_values = target_values.view(-1).to(\"cpu\")\n",
    "pred_values = pred_values.view(-1).to(\"cpu\")\n",
    "pred_std = pred_std.view(-1).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9209a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata = np.asarray([target_values.detach().numpy(),pred_values.detach().numpy(),pred_std.detach().numpy(),all_models,all_noises])\n",
    "savename = f\"plotdata/{dim}d_\"+f\"regression_length{T}\"\n",
    "if dim == 1:\n",
    "    savename = f\"plotdata/regression_length{T}\"\n",
    "np.savetxt(savename,plotdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_models)\n",
    "\n",
    "per_model_mse = np.zeros(5)\n",
    "per_model_mae = np.zeros(5)\n",
    "per_model_predvar = np.zeros(5)\n",
    "model_count = np.zeros(5)\n",
    "\n",
    "for i in tqdm(range(len(target_values))):\n",
    "    per_model_mae[int(all_models[i])] += abs(target_values[i]-pred_values[i])\n",
    "    per_model_mse[int(all_models[i])] += np.square(target_values[i]-pred_values[i])\n",
    "    per_model_predvar[int(all_models[i])] += pred_std[i]**2\n",
    "    model_count[int(all_models[i])] += 1\n",
    "    \n",
    "per_model_mae = per_model_mae/model_count\n",
    "per_model_mse = per_model_mse/model_count\n",
    "per_model_predvar = per_model_predvar/model_count\n",
    "\n",
    "print(per_model_mae)\n",
    "print(per_model_mse)\n",
    "print(per_model_predvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "x_val = [0,1,2,3,4]\n",
    "classes = ['attm', 'ctrw', 'fbm', 'lw', 'sbm']\n",
    "\n",
    "plt.plot(x_val,per_model_mae,\"o\",ms = 11)\n",
    "plt.xticks(ticks=x_val, labels=classes, size = 16)\n",
    "plt.ylabel(\"MAE\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/MAE_per_model.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/MAE_per_model.svg\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/correctnoise/MAE_per_model.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/correctnoise/MAE_per_model.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "x_val = [0,1,2,3,4]\n",
    "classes = ['attm', 'ctrw', 'fbm', 'lw', 'sbm']\n",
    "\n",
    "plt.plot(x_val,per_model_mse,\"o\",ms = 11,label=\"observed error\")\n",
    "plt.plot(x_val,per_model_predvar,\"o\",ms = 11, label=\"predicted error\")\n",
    "plt.xticks(ticks=x_val, labels=classes, size = 16)\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/MSE_per_model_with_pred.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/MSE_per_model_with_pred.svg\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/correctnoise/MSE_per_model_with_pred.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/correctnoise/MSE_per_model_with_pred.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f9182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = [0.1,0.5,1]\n",
    "\n",
    "per_noise_mse = np.zeros(3)\n",
    "per_noise_mae = np.zeros(3)\n",
    "per_noise_predvar = np.zeros(3)\n",
    "noise_count = np.zeros(3)\n",
    "\n",
    "for i in range(len(target_values)):\n",
    "    index = int(2*all_noises[i]+0.1)\n",
    "    \n",
    "    per_noise_mae[index] += abs(target_values[i]-pred_values[i])\n",
    "    per_noise_mse[index] += np.square(target_values[i]-pred_values[i])\n",
    "    per_noise_predvar[index] += pred_std[i]**2\n",
    "    noise_count[index] += 1\n",
    "    \n",
    "per_noise_mae = per_noise_mae/noise_count\n",
    "per_noise_mse = per_noise_mse/noise_count\n",
    "per_noise_predvar = per_noise_predvar/noise_count\n",
    "\n",
    "print(per_noise_mae)\n",
    "print(per_noise_mse)\n",
    "print(per_noise_predvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b200a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "x_val = [0,1,2]\n",
    "classes = ['SNR 10', 'SNR 2', 'SNR 1']\n",
    "\n",
    "plt.plot(x_val,per_noise_mae,\"o\",ms = 11)\n",
    "plt.xticks(ticks=x_val, labels=classes, size = 16)\n",
    "plt.ylabel(\"MAE\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/MAE_per_noise.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/MAE_per_noise.svg\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/correctnoise/MAE_per_noise.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/correctnoise/MAE_per_noise.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fb8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "x_val = [0,1,2]\n",
    "classes = ['SNR 10', 'SNR 2', 'SNR 1']\n",
    "\n",
    "plt.plot(x_val,per_noise_mse,\"o\",ms = 11,label=\"observed error\")\n",
    "plt.plot(x_val,per_noise_predvar,\"o\",ms = 11, label=\"predicted error\")\n",
    "plt.xticks(ticks=x_val, labels=classes, size = 16)\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/MSE_per_noise_with_pred.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/MSE_per_noise_with_pred.svg\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/correctnoise/MSE_per_noise_with_pred.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/correctnoise/MSE_per_noise_with_pred.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b70102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#observed error over predicted error\n",
    "predicted_errors = torch.arange(0.,1,0.02)\n",
    "observed_errors = torch.zeros(len(predicted_errors))\n",
    "n_interval = torch.zeros(len(predicted_errors))\n",
    "\n",
    "for l in range(len(target_values)):\n",
    "    index = torch.where(predicted_errors <= pred_std[l].item())[-1][-1]\n",
    "    #print(index,pred_std[l]**2)\n",
    "    n_interval[index] += 1\n",
    "    observed_errors[index] += torch.square(target_values[l] - pred_values[l])\n",
    "\n",
    "for l in range(len(predicted_errors)):\n",
    "    if n_interval[l] > 50:\n",
    "        observed_errors[l] = np.sqrt(observed_errors[l]/n_interval[l])\n",
    "    else:\n",
    "        observed_errors[l] = np.nan\n",
    "print(observed_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "\n",
    "plt.plot(predicted_errors+0.01,observed_errors,\"o-\",linewidth=0.7)\n",
    "plt.plot(predicted_errors,predicted_errors,\"grey\")\n",
    "\n",
    "plt.xlim(0,0.7)\n",
    "plt.ylim(0,0.7)\n",
    "#plt.legend()\n",
    "plt.xlabel(\"Predicted standard deviation\")\n",
    "plt.ylabel(\"Observed standard deviation\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/conf_acc.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/conf_acc.svg\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/correctnoise/conf_acc.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/correctnoise/conf_acc.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c62ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values\n",
    "target_values\n",
    "pred_std\n",
    "alpha_gts = torch.arange(0.05,2.05,0.05)\n",
    "predval_per_gt_and_model = torch.zeros(5,len(alpha_gts))\n",
    "predvar_per_gt_and_model = torch.zeros(5,len(alpha_gts))\n",
    "ncount_per_gt_and_model = torch.zeros(5,len(alpha_gts))\n",
    "for i in range(len(pred_values)):\n",
    "    condition = target_values[i].item() - 0.025 <= alpha_gts\n",
    "    index = torch.where(condition)[-1]\n",
    "    if len(index) > 1:\n",
    "        index = index[0]\n",
    "    predval_per_gt_and_model[int(all_models[i]),index] += pred_values[i]\n",
    "    predvar_per_gt_and_model[int(all_models[i]),index] += pred_std[i]**2\n",
    "    ncount_per_gt_and_model[int(all_models[i]),index] += 1\n",
    "\n",
    "    \n",
    "predval_per_gt = predval_per_gt_and_model.sum(axis=0)/ncount_per_gt_and_model.sum(axis=0)\n",
    "predvar_per_gt = predvar_per_gt_and_model.sum(axis=0)/ncount_per_gt_and_model.sum(axis=0)\n",
    "print(predval_per_gt)\n",
    "predval_per_gt_and_model = predval_per_gt_and_model/ncount_per_gt_and_model\n",
    "predvar_per_gt_and_model = predvar_per_gt_and_model/ncount_per_gt_and_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "\n",
    "plt.plot(alpha_gts ,predval_per_gt_and_model[0] ,\"o-\" ,markersize=6 ,linewidth=0.7 ,label=\"ATTM\")\n",
    "plt.plot(alpha_gts ,predval_per_gt_and_model[1] ,\"v-\" ,markersize=6 ,linewidth=0.7 ,label=\"CTRW\")\n",
    "plt.plot(alpha_gts ,predval_per_gt_and_model[2] ,\"<-\" ,markersize=6 ,linewidth=0.7 ,label=\"FBM\")\n",
    "plt.plot(alpha_gts ,predval_per_gt_and_model[3] ,\"s-\" ,markersize=6 ,linewidth=0.7 ,label=\"LW\")\n",
    "plt.plot(alpha_gts ,predval_per_gt_and_model[4] ,\"d-\" ,markersize=6 ,linewidth=0.7 , label=\"SBM\")\n",
    "plt.plot(alpha_gts ,alpha_gts ,\"-\" ,color=\"grey\" ,markersize=7 ,linewidth=0.7 ,label=\"Truth\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"True Exponent \"+r\"$\\alpha$\")\n",
    "plt.ylabel(\"Predicted Exponent \"+r\"$\\alpha$\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/alphapred_over_gt.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/alphapred_over_gt.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "#print(predval_per_gt_and_model.mean(axis=1))\n",
    "\n",
    "#plt.plot(alpha_gts ,predval_per_gt ,\"o-\" ,markersize=6 ,linewidth=0.7 ,label=\"all models\")\n",
    "plt.errorbar(alpha_gts,predval_per_gt,predvar_per_gt**(0.5),marker=\"o\",label=\"All model average\")\n",
    "plt.plot(alpha_gts ,alpha_gts ,\"-\" ,color=\"grey\" ,markersize=7 ,linewidth=0.7 ,label=\"Truth\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"True Exponent \"+r\"$\\alpha$\")\n",
    "plt.ylabel(\"Predicted Exponent \"+r\"$\\alpha$\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/alphapred_over_gt_all_models_errorbar.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/alphapred_over_gt_all_models_errorbar.svg\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#observed error over predicted error\n",
    "predicted_errors = torch.arange(0.,1,0.02)\n",
    "observed_errors = torch.zeros(len(predicted_errors))\n",
    "n_interval = torch.zeros(len(predicted_errors))\n",
    "n_interval_per_model = torch.zeros(5,len(predicted_errors))\n",
    "\n",
    "for l in range(len(target_values)):\n",
    "    index = torch.where(predicted_errors <= pred_std[l].item())[-1][-1]\n",
    "    #print(index,pred_std[l]**2)\n",
    "    n_interval[index] += 1\n",
    "    observed_errors[index] += torch.square(target_values[l] - pred_values[l])\n",
    "    n_interval_per_model[int(all_models[l]),index] += 1\n",
    "\n",
    "for l in range(len(predicted_errors)):\n",
    "    if n_interval[l] > 50:\n",
    "        observed_errors[l] = np.sqrt(observed_errors[l]/n_interval[l])\n",
    "    else:\n",
    "        observed_errors[l] = np.nan\n",
    "print(observed_errors)\n",
    "print(n_interval_per_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16) \n",
    "\n",
    "models = [\"attm\",\"ctrw\",\"fbm\",\"lw\",\"sbm\"]\n",
    "plt.bar(predicted_errors,n_interval,width=0.02)\n",
    "plt.show()\n",
    "y_offset = np.zeros((len(n_interval_per_model[0])))\n",
    "for model in range(5):\n",
    "    plt.bar(predicted_errors,n_interval_per_model[model],width=0.02,bottom=y_offset,label=models[model])\n",
    "    y_offset = y_offset + np.asarray(n_interval_per_model[model])\n",
    "plt.legend()\n",
    "plt.xlabel(\"predicted error (std)\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "#plot only sbm,fbm\n",
    "for model in range(5):\n",
    "    plt.plot(predicted_errors,n_interval_per_model[model],label=models[model])\n",
    "plt.legend()\n",
    "plt.xlabel(\"predicted error (std)\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adec465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174f819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53225ab2",
   "metadata": {},
   "source": [
    "### Now for fbm and sbm only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from swag.posteriors import swag as swag\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "%run load_andi_dataset.ipynb\n",
    "%run LSTM_Neural_Network.ipynb\n",
    "%run swag_lr_scheduler.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf30c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration, run on gpu if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Hyper-parameters, neuralnet parameters need to match the loaded model! \n",
    "input_dim = 1 # 1D input sequence\n",
    "LSTM_size = 64\n",
    "output_dim = 2 #output size\n",
    "batch_size = 500\n",
    "\n",
    "number_swags = 5 #number of swag models in multi swag ensemble\n",
    "number_mc_samples = 10 #number of samples taken per swag model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c10cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "super_dataset = AnDi_super_dataset(path = \"datasets/super/1dim_100lenght/\", fname = \"andiset50000_sbmfbm.txt\", dim=1)\n",
    "#super_dataset = AnDi_super_dataset(path = \"datasets/super/1dim_100lenght/\", fname = \"andiset50000_sbmfbm_correctnoise.txt\", dim=1)\n",
    "print(len(super_dataset))\n",
    "super_loader = torch.utils.data.DataLoader(dataset=super_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3c0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataset example\n",
    "ex_models,ex_exponents,ex_noise,ex_traj = iter(super_loader).next()\n",
    "print(ex_models[0],ex_exponents[0],ex_noise[0],ex_traj[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models:\n",
    "checkpoints_path = \"saves/aleatoric/multi/\"\n",
    "\n",
    "swag_model = swag.SWAG(LSTM_Regression_aleatoric, subspace_type = 'covariance', \n",
    "                       subspace_kwargs={'max_rank': 20}, num_input_features = input_dim, \n",
    "                      output_dim = output_dim, LSTM_size=LSTM_size)\n",
    "#swag_model.to(device)\n",
    "\n",
    "#swag_model.subspace.rank = torch.tensor(0)\n",
    "#swag_model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "#swag_model.eval()\n",
    "\n",
    "multi_swag_models = []\n",
    "for i in range(number_swags):\n",
    "    swag_model = swag.SWAG(LSTM_Regression_aleatoric, subspace_type = 'covariance', \n",
    "                       subspace_kwargs={'max_rank': 20}, num_input_features = input_dim, \n",
    "                      output_dim = output_dim, LSTM_size=LSTM_size)\n",
    "    swag_model.to(device)\n",
    "    swag_model.subspace.rank = torch.tensor(0)\n",
    "    \n",
    "    \n",
    "    name = \"swag_modelcheckpoint_multiswag%s\" % i\n",
    "    savefile = checkpoints_path + name\n",
    "    \n",
    "    swag_model.load_state_dict(torch.load(savefile,map_location=device))\n",
    "    \n",
    "    swag_model.eval()\n",
    "    \n",
    "    \n",
    "    multi_swag_models.append(swag_model)\n",
    "\n",
    "#mse loss and Gaussian negative log likelihood criterion\n",
    "MSELoss = nn.MSELoss()\n",
    "criterion = torch.nn.GaussianNLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test multi swag model on super data set\n",
    "n_test_steps = len(super_loader)\n",
    "n_total_samples = len(super_dataset)\n",
    "number_swags = len(multi_swag_models)\n",
    "\n",
    "target_values = torch.zeros(n_test_steps,batch_size).to(device)\n",
    "pred_values = torch.zeros(n_test_steps,batch_size).to(device)\n",
    "pred_std = torch.zeros(n_test_steps,batch_size).to(device)\n",
    "all_models = np.array([])\n",
    "all_noises = np.array([])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_abserr = 0\n",
    "    n_samples = 0\n",
    "    acc_loss = 0\n",
    "    acc_pred_var = 0\n",
    "    acc_mse = 0\n",
    "    for j, (models, targets, noise, traj) in enumerate(tqdm.tqdm(super_loader)):\n",
    "        all_models = np.append(all_models,models)\n",
    "        all_noises = np.append(all_noises,noise)\n",
    "        traj = traj.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        output_samples = torch.ones(number_swags*number_mc_samples, len(traj), 1, dtype=torch.float32).to(device)\n",
    "        variance_samples = torch.ones(number_swags*number_mc_samples, len(traj), 1, dtype=torch.float32).to(device)\n",
    "        for k in range(number_swags):\n",
    "            for i in range(number_mc_samples):\n",
    "                multi_swag_models[k].sample()\n",
    "                model_output = multi_swag_models[k](traj)\n",
    "                output_samples[k*number_mc_samples+i] = model_output[:,0].view(-1,1)\n",
    "                variance_samples[k*number_mc_samples+i] = model_output[:,1].view(-1,1)\n",
    "        \n",
    "        outputs = output_samples.mean(0)\n",
    "        outputted_var = variance_samples.mean(0)\n",
    "        combined_var = output_samples.var(0) + outputted_var\n",
    "        \n",
    "        target_values[j] = targets.view(len(traj))\n",
    "        pred_values[j] = outputs.view(len(traj))\n",
    "        pred_std[j] = torch.sqrt(combined_var).view(len(traj))\n",
    "        \n",
    "        \n",
    "        acc_pred_var += combined_var.sum().item()\n",
    "        \"\"\"if epoch+1 >= swag_start:\n",
    "            swag_model.set_swa()\n",
    "            outputs = swag_model(traj)\n",
    "        else:\n",
    "            outputs = model(traj)\"\"\"\n",
    "            \n",
    "        acc_loss += criterion(outputs, targets, outputted_var).item()\n",
    "        acc_mse += MSELoss(outputs,targets)\n",
    "        n_samples += targets.size(0)\n",
    "        n_abserr += (outputs-targets).abs().sum().item()\n",
    "        \n",
    "\n",
    "    MAE = n_abserr / n_samples\n",
    "    mean_loss = acc_loss/n_test_steps\n",
    "    mean_pred_var = acc_pred_var/n_samples\n",
    "    mean_mse = acc_mse/n_test_steps\n",
    "    print(f'MAE of the network on the 100000 test trajectories: {MAE}')\n",
    "    print(f'Mean loss is: {mean_loss}')\n",
    "    print(f'Mean Squared Error is: {mean_mse}')\n",
    "    print(f'Mean Variance predicted by SWAG is: {mean_pred_var}')\n",
    "    \n",
    "target_values = target_values.view(-1).to(\"cpu\")\n",
    "pred_values = pred_values.view(-1).to(\"cpu\")\n",
    "pred_std = pred_std.view(-1).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0745c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_models)\n",
    "\n",
    "per_model_mse = np.zeros(5)\n",
    "per_model_mae = np.zeros(5)\n",
    "per_model_predvar = np.zeros(5)\n",
    "model_count = np.zeros(5)\n",
    "\n",
    "for i in range(len(target_values)):\n",
    "    per_model_mae[int(all_models[i])] += abs(target_values[i]-pred_values[i])\n",
    "    per_model_mse[int(all_models[i])] += np.square(target_values[i]-pred_values[i])\n",
    "    per_model_predvar[int(all_models[i])] += pred_std[i]**2\n",
    "    model_count[int(all_models[i])] += 1\n",
    "    \n",
    "per_model_mae = per_model_mae/model_count\n",
    "per_model_mse = per_model_mse/model_count\n",
    "per_model_predvar = per_model_predvar/model_count\n",
    "\n",
    "print(per_model_mae)\n",
    "print(per_model_mse)\n",
    "print(per_model_predvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317158aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "x_val = [0,1,2,3,4]\n",
    "classes = ['attm', 'ctrw', 'fbm', 'lw', 'sbm']\n",
    "\n",
    "plt.plot(x_val,per_model_mae,\"o\",ms = 11)\n",
    "plt.xticks(ticks=x_val, labels=classes, size = 16)\n",
    "plt.ylabel(\"MAE\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/sbmfbm_only/MAE_per_model.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/sbmfbm_only/MAE_per_model.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "x_val = [0,1,2,3,4]\n",
    "classes = ['attm', 'ctrw', 'fbm', 'lw', 'sbm']\n",
    "\n",
    "plt.plot(x_val,per_model_mse,\"o\",ms = 11,label=\"observed error\")\n",
    "plt.plot(x_val,per_model_predvar,\"o\",ms = 11, label=\"predicted error\")\n",
    "plt.xticks(ticks=x_val, labels=classes, size = 16)\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/sbmfbm_only/MSE_per_model_with_pred.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/sbmfbm_only/MSE_per_model_with_pred.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d131367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2885b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = [0.1,0.5,1]\n",
    "\n",
    "per_noise_mse = np.zeros(3)\n",
    "per_noise_mae = np.zeros(3)\n",
    "per_noise_predvar = np.zeros(3)\n",
    "noise_count = np.zeros(3)\n",
    "\n",
    "for i in range(len(target_values)):\n",
    "    index = int(2*all_noises[i]+0.1)\n",
    "    \n",
    "    per_noise_mae[index] += abs(target_values[i]-pred_values[i])\n",
    "    per_noise_mse[index] += np.square(target_values[i]-pred_values[i])\n",
    "    per_noise_predvar[index] += pred_std[i]**2\n",
    "    noise_count[index] += 1\n",
    "    \n",
    "per_noise_mae = per_noise_mae/noise_count\n",
    "per_noise_mse = per_noise_mse/noise_count\n",
    "per_noise_predvar = per_noise_predvar/noise_count\n",
    "\n",
    "print(per_noise_mae)\n",
    "print(per_noise_mse)\n",
    "print(per_noise_predvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b9552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "x_val = [0,1,2]\n",
    "classes = ['SNR 10', 'SNR 2', 'SNR 1']\n",
    "\n",
    "plt.plot(x_val,per_noise_mae,\"o\",ms = 11)\n",
    "plt.xticks(ticks=x_val, labels=classes, size = 16)\n",
    "plt.ylabel(\"MAE\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/sbmfbm_only/MAE_per_noise.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/sbmfbm_only/MAE_per_noise.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63682af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "x_val = [0,1,2]\n",
    "classes = ['SNR 10', 'SNR 2', 'SNR 1']\n",
    "\n",
    "plt.plot(x_val,per_noise_mse,\"o\",ms = 11,label=\"observed error\")\n",
    "plt.plot(x_val,per_noise_predvar,\"o\",ms = 11, label=\"predicted error\")\n",
    "plt.xticks(ticks=x_val, labels=classes, size = 16)\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/sbmfbm_only/MSE_per_noise_with_pred.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/sbmfbm_only/MSE_per_noise_with_pred.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#observed error over predicted error\n",
    "predicted_errors = torch.arange(0.,1,0.02)\n",
    "observed_errors = torch.zeros(len(predicted_errors))\n",
    "n_interval = torch.zeros(len(predicted_errors))\n",
    "\n",
    "for l in range(len(target_values)):\n",
    "    index = torch.where(predicted_errors <= pred_std[l].item())[-1][-1]\n",
    "    #print(index,pred_std[l]**2)\n",
    "    n_interval[index] += 1\n",
    "    observed_errors[index] += torch.square(target_values[l] - pred_values[l])\n",
    "\n",
    "for l in range(len(predicted_errors)):\n",
    "    if n_interval[l] > 50:\n",
    "        observed_errors[l] = np.sqrt(observed_errors[l]/n_interval[l])\n",
    "    else:\n",
    "        observed_errors[l] = np.nan\n",
    "print(observed_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a166da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=16)  \n",
    "\n",
    "\n",
    "plt.plot(predicted_errors+0.01,observed_errors,\"o-\",linewidth=0.7)\n",
    "plt.plot(predicted_errors,predicted_errors,\"grey\")\n",
    "\n",
    "plt.xlim(0,0.6)\n",
    "plt.ylim(0,0.6)\n",
    "#plt.legend()\n",
    "plt.xlabel(\"Predicted standard deviation\")\n",
    "plt.ylabel(\"Observed standard deviation\")\n",
    "\n",
    "#plt.savefig(\"figs/super_evaluate/regression/sbmfbm_only/conf_acc.png\")\n",
    "#plt.savefig(\"figs/super_evaluate/regression/sbmfbm_only/conf_acc.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225d95f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
